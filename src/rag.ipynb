{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "#Init Libraries\n",
    "\n",
    "#Fitting Libraries\n",
    "from components import Components\n",
    "from llama_index.core import Settings\n",
    "\n",
    "#Additional Core Libraries\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.core.ingestion import IngestionPipeline\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.core import PromptTemplate,Document \n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialise components, reranker and retriever\n",
    "rag_components = Components(\"Snowflake/snowflake-arctic-embed-s\",\"mixedbread-ai/mxbai-embed-large-v1\",\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'llama3-8b-8192'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_components.model_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting Contexts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding model loaded!\n",
      "LLM model loaded!\n"
     ]
    }
   ],
   "source": [
    "Settings.embed_model = rag_components.get_embedding_model()\n",
    "Settings.llm = rag_components.get_groq_llm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = ChromaVectorStore(chroma_collection=rag_components.get_db())\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading Papers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/MainDataset/data/Context.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_list = []\n",
    "for contexts in df['context']:\n",
    "    context_list.append(Document(text=contexts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = IngestionPipeline(\n",
    "    transformations=[\n",
    "          SentenceSplitter(chunk_size=512, chunk_overlap=128),\n",
    "    ],\n",
    "    vector_store=vector_store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = pipeline.run(documents=context_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = VectorStoreIndex(documents, storage_context=storage_context,similarity_top_k=5) #node_postprocessors=[rag_components.get_reranker()]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(streaming=True,similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "qa_prompt_template_str = \"\"\"\n",
    "Context: {context_str}\n",
    "Instructions:\n",
    "- Be helpful and answer questions concisely. If you don't know the answer, say 'I don't know'\n",
    "- Utilize the context provided for accurate and specific information.\n",
    "- Incorporate your preexisting knowledge to enhance the depth and relevance of your response.\n",
    "- Be concise and to the point.\n",
    "Question: {query_str}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "qa_prompt_template = PromptTemplate(qa_prompt_template_str)\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\":qa_prompt_template}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:refine_template\":PromptTemplate(\"\")}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qa = pd.read_csv('../data/MainDataset/data/QA.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_list = []\n",
    "for questions in df_qa['question']:\n",
    "    question_list.append(questions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "who introduced modern methods of surgery, such as antiseptics, sterilization, and washing hands? brainly\n",
      "According to the provided context, Joseph Lister introduced modern methods of surgery, such as antiseptics, sterilization, and washing hands, with his paper \"Antiseptic Principle of the Practice of Surgery\" in 1867.\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "0/128\n",
      "president adams\n"
     ]
    },
    {
     "ename": "ValidationError",
     "evalue": "1 validation error for LLMCompletionEndEvent\nresponse\n  none is not an allowed value (type=type_error.none.not_allowed)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValidationError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(question_list[i])\n\u001b[0;32m      5\u001b[0m response \u001b[38;5;241m=\u001b[39m query_engine\u001b[38;5;241m.\u001b[39mquery(question_list[i])\n\u001b[1;32m----> 6\u001b[0m \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_response_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m rowIndex \u001b[38;5;241m=\u001b[39m df_qa\u001b[38;5;241m.\u001b[39mindex[i]\n\u001b[0;32m      9\u001b[0m df_qa\u001b[38;5;241m.\u001b[39mat[rowIndex, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgen_answer\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mresponse_txt\n",
      "File \u001b[1;32me:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\llama_index\\core\\base\\response\\schema.py:142\u001b[0m, in \u001b[0;36mStreamingResponse.print_response_stream\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_txt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_gen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    141\u001b[0m     response_txt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 142\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m text \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresponse_gen:\n\u001b[0;32m    143\u001b[0m         \u001b[38;5;28mprint\u001b[39m(text, end\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m, flush\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m    144\u001b[0m         response_txt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m text\n",
      "File \u001b[1;32me:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\llama_index\\core\\llms\\llm.py:116\u001b[0m, in \u001b[0;36mstream_chat_response_to_tokens.<locals>.gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m TokenGen:\n\u001b[1;32m--> 116\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m chat_response_gen:\n\u001b[0;32m    117\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m response\u001b[38;5;241m.\u001b[39mdelta \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32me:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:185\u001b[0m, in \u001b[0;36mllm_chat_callback.<locals>.wrap.<locals>.wrapped_llm_chat.<locals>.wrapped_gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m    183\u001b[0m last_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    184\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m f_return_val:\n\u001b[0;32m    186\u001b[0m         dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[0;32m    187\u001b[0m             LLMChatInProgressEvent(\n\u001b[0;32m    188\u001b[0m                 messages\u001b[38;5;241m=\u001b[39mmessages,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    191\u001b[0m             )\n\u001b[0;32m    192\u001b[0m         )\n\u001b[0;32m    193\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m cast(ChatResponse, x)\n",
      "File \u001b[1;32me:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\llama_index\\core\\base\\llms\\generic_utils.py:73\u001b[0m, in \u001b[0;36mstream_completion_response_to_chat_response.<locals>.gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatResponseGen:\n\u001b[1;32m---> 73\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m response \u001b[38;5;129;01min\u001b[39;00m completion_response_gen:\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m ChatResponse(\n\u001b[0;32m     75\u001b[0m             message\u001b[38;5;241m=\u001b[39mChatMessage(\n\u001b[0;32m     76\u001b[0m                 role\u001b[38;5;241m=\u001b[39mMessageRole\u001b[38;5;241m.\u001b[39mASSISTANT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     81\u001b[0m             raw\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mraw,\n\u001b[0;32m     82\u001b[0m         )\n",
      "File \u001b[1;32me:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\llama_index\\core\\llms\\callbacks.py:474\u001b[0m, in \u001b[0;36mllm_completion_callback.<locals>.wrap.<locals>.wrapped_llm_predict.<locals>.wrapped_gen\u001b[1;34m()\u001b[0m\n\u001b[0;32m    464\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m    465\u001b[0m callback_manager\u001b[38;5;241m.\u001b[39mon_event_end(\n\u001b[0;32m    466\u001b[0m     CBEventType\u001b[38;5;241m.\u001b[39mLLM,\n\u001b[0;32m    467\u001b[0m     payload\u001b[38;5;241m=\u001b[39m{\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    471\u001b[0m     event_id\u001b[38;5;241m=\u001b[39mevent_id,\n\u001b[0;32m    472\u001b[0m )\n\u001b[0;32m    473\u001b[0m dispatcher\u001b[38;5;241m.\u001b[39mevent(\n\u001b[1;32m--> 474\u001b[0m     \u001b[43mLLMCompletionEndEvent\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    475\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    476\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlast_response\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    477\u001b[0m \u001b[43m        \u001b[49m\u001b[43mspan_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mspan_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    478\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    479\u001b[0m )\n",
      "File \u001b[1;32me:\\Github Repositories\\RAG-FYP2024\\.venv\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001b[0m, in \u001b[0;36mBaseModel.__init__\u001b[1;34m(__pydantic_self__, **data)\u001b[0m\n\u001b[0;32m    339\u001b[0m values, fields_set, validation_error \u001b[38;5;241m=\u001b[39m validate_model(__pydantic_self__\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m, data)\n\u001b[0;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m validation_error:\n\u001b[1;32m--> 341\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m validation_error\n\u001b[0;32m    342\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    343\u001b[0m     object_setattr(__pydantic_self__, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__dict__\u001b[39m\u001b[38;5;124m'\u001b[39m, values)\n",
      "\u001b[1;31mValidationError\u001b[0m: 1 validation error for LLMCompletionEndEvent\nresponse\n  none is not an allowed value (type=type_error.none.not_allowed)"
     ]
    }
   ],
   "source": [
    "import time\n",
    "for i in range(len(question_list)): \n",
    "    time.sleep(3)\n",
    "    print(question_list[i])\n",
    "    response = query_engine.query(question_list[i])\n",
    "    response.print_response_stream()\n",
    "    rowIndex = df_qa.index[i]\n",
    "\n",
    "    df_qa.at[rowIndex, 'gen_answer'] = response.response_txt\n",
    "    print('')\n",
    "    print(\"--\"*100)\n",
    "    print(f'{i}/{128}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question</th>\n",
       "      <th>answers</th>\n",
       "      <th>gen_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>who introduced modern methods of surgery, such...</td>\n",
       "      <td>Joseph Lister</td>\n",
       "      <td>According to the context, Joseph Lister introd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>what kind of government was chiang kai-shek tr...</td>\n",
       "      <td>Chiang Kai-Shek was trying to build a Communis...</td>\n",
       "      <td>According to the context, Chiang Kai-shek was ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>president adams</td>\n",
       "      <td>John Quincy Adams was an American statesman wh...</td>\n",
       "      <td>You're referring to John Quincy Adams, the 6th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>define semitic</td>\n",
       "      <td>A member of any of a number of peoples of anci...</td>\n",
       "      <td>According to the provided context, a Semite re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>what is wudfhost service</td>\n",
       "      <td>It is a set of Microsoft tools that aid in the...</td>\n",
       "      <td>The WUDFHost.exe is a process that belongs to ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>151</th>\n",
       "      <td>In modern times, what is said about civil diso...</td>\n",
       "      <td>['become utterly debased', 'utterly debased', ...</td>\n",
       "      <td>According to the text, in modern times, the te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>Who noted the different current uses of civil ...</td>\n",
       "      <td>['Marshall Cohen', 'Marshall Cohen', 'Marshall...</td>\n",
       "      <td>According to the text, Vice President Agnew no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>How has civil disobedience evolved in current ...</td>\n",
       "      <td>['code-word describing the activities of mugge...</td>\n",
       "      <td>According to the text, civil disobedience has ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>Who gave a negative connotation to civil disob...</td>\n",
       "      <td>['Vice President Agnew', 'Vice President Agnew...</td>\n",
       "      <td>According to the text, Vice President Agnew ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>What issue has been plaguing the civil disobed...</td>\n",
       "      <td>['ambiguity', 'ambiguity', 'ambiguity', 'ambig...</td>\n",
       "      <td>According to the text, the issue plaguing the ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>156 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              question  \\\n",
       "0    who introduced modern methods of surgery, such...   \n",
       "1    what kind of government was chiang kai-shek tr...   \n",
       "2                                      president adams   \n",
       "3                                       define semitic   \n",
       "4                             what is wudfhost service   \n",
       "..                                                 ...   \n",
       "151  In modern times, what is said about civil diso...   \n",
       "152  Who noted the different current uses of civil ...   \n",
       "153  How has civil disobedience evolved in current ...   \n",
       "154  Who gave a negative connotation to civil disob...   \n",
       "155  What issue has been plaguing the civil disobed...   \n",
       "\n",
       "                                               answers  \\\n",
       "0                                        Joseph Lister   \n",
       "1    Chiang Kai-Shek was trying to build a Communis...   \n",
       "2    John Quincy Adams was an American statesman wh...   \n",
       "3    A member of any of a number of peoples of anci...   \n",
       "4    It is a set of Microsoft tools that aid in the...   \n",
       "..                                                 ...   \n",
       "151  ['become utterly debased', 'utterly debased', ...   \n",
       "152  ['Marshall Cohen', 'Marshall Cohen', 'Marshall...   \n",
       "153  ['code-word describing the activities of mugge...   \n",
       "154  ['Vice President Agnew', 'Vice President Agnew...   \n",
       "155  ['ambiguity', 'ambiguity', 'ambiguity', 'ambig...   \n",
       "\n",
       "                                            gen_answer  \n",
       "0    According to the context, Joseph Lister introd...  \n",
       "1    According to the context, Chiang Kai-shek was ...  \n",
       "2    You're referring to John Quincy Adams, the 6th...  \n",
       "3    According to the provided context, a Semite re...  \n",
       "4    The WUDFHost.exe is a process that belongs to ...  \n",
       "..                                                 ...  \n",
       "151  According to the text, in modern times, the te...  \n",
       "152  According to the text, Vice President Agnew no...  \n",
       "153  According to the text, civil disobedience has ...  \n",
       "154  According to the text, Vice President Agnew ga...  \n",
       "155  According to the text, the issue plaguing the ...  \n",
       "\n",
       "[156 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_qa.to_csv(f'../data/MainDataset/results/{rag_components.model_name}_RAG_Run1.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
